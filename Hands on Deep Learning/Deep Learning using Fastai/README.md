# Deep-Learning - This repository contains codes to train deep learning frameworks for different applications.

## Deep Learning using Fastai
| # | **File name** |  **Description** |
| ---------- |--------- | ------------------------------------------------| 
|1|[Pet_breed_classification](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Pet_breed_classification.ipynb)|Code to train Resnet-34 and Resnet-50 models for cat vs. dog breed classification problem. This code includes 1-cycle learning rate adaptation policy and did classification on 37 breeds.|
|2|[MNIST_classification](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/MNIST_classification.ipynb)|Code to train Resnet-18 model for MNIST digit classification.|
|3|[Download_and_classify_data_from_web](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Download_and%20classify_data_from_web.ipynb)|Code to download (from web) and classify (using deep neural network) images of 3 sweets. Also it demonstrates how to clean up the data by visualizing misclassified images.|
|4|[SGD_linear_regression](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/SGD_linear_regression.ipynb)|Stochastic gradient descent on regression problem.|
|5|[Multi-label prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Multi-label%20prediction.ipynb)|Multi-label prediction using Resnet-50 model on Planet Amazon dataset obtained from [Kaggle](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space).|
|6|[Image_Segmentation](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Image_Segmentation.ipynb)|Image segmentation using U-Net and with Resnet-18 enncoder on Camvid dataset.|




## Ipython notebooks of [Deep Neural Networks with PyTorch](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/home/welcome)
| # | **File name** |  **Description** |
| ---------- |--------- | ------------------------------------------------| 
|1|[1D_tensors](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L1_1D_tensors.ipynb)| Basic operations on 1D tensors|
|2|[2D_tensors](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L2_Two-Dimensional_Tensors.ipynb)| Basic operations on 2D tensors|
|3|[Derivatives](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L3_derivativesandGraphsinPytorch.ipynb)| Derivatives in Pytorch|
|4|[Toy_dataset](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L4_simple_data_set.ipynb)| Creating a toy dataset in Pytorch, compose and perform transformations on it|
|5|[Datasets_and_transforms](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L5_Datasets_and_transforms.ipynb)| Build an image dataset object and perform pre-build transformations using torchvision.transforms on it|
|6|[MNIST_data_&_transforms](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L6_pre-Built%20Datasets_and_transforms.ipynb)| How to use pre-built MNIST dataset and perform transformations on it|
|7|[Regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L7_prediction_on_1D_input.ipynb)| Make predictions for multiple 1D inputs using linear class|
|8|[1D_Linear_regression_1_parameter](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L8_linear_regression_one_parameter.ipynb)| Create linear regression model using 1 parameter, cost/criterion function using MSE, and plot parameters as well as loss values|
|9|[1D_Linear_regression_2_parameters](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L9_training_slope_and_bias.ipynb)| 1D Linear regression model using 2 parameters (w and b). Visualize the data space and the parameter space during training via batch gradient descent|
|10|[Stochastic_gradient_descent](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L10_stochastic_gradient_descent.ipynb)| 1D Linear regression using stochastic gradient descent|
|11|[Mini_batch_gradient_descent](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L11_mini-batch_gradient_descent.ipynb)| 1D Linear regression using mini-batch gradient descent. This code also includes comparison between batch, stochastic and mini-batch gradient descent with different batch sizes|
|12|[Mini_batch_gradient_descent2](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L12_PyTorchway.ipynb)| 1D Linear regression using  PyTorch build-in functions|
|13|[Models_with_different_LR](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L13_Models_with_different_LR.ipynb)| 1D Linear regression with different learning rates and view results such as training and validation losses at different LR|
|14|[Multiple_linear_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L14_multiple_linear_regression_prediction.ipynb)| Multiple linear regression prediction (preparing forward propagation with 1xn tensor input)|
|15|[Multiple_linear_regression_training](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L15_multiple_linear_regression_training.ipynb)| Multiple linear regression training with input of 1xn tensor|
|16|[Multi_target_linear_regression](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L16_multi-target_linear_regression.ipynb)| Multiple target linear regression prediction (forward propagation)|
|17|[training_multiple_output_linear_regression](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L17_training_multiple_output_linear_regression.ipynb)| pytorch build in functions to train multiple target linear regression|
|18|[logistic_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L18_logistic_regression_prediction.ipynb)| Prediction using sigmoid/logistic function|
|19|[logistic_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L19_Bad_initialization_logistic_regression_with_mean_square_error.ipynb)| Illustration of poor performance of logistic regression via bad parameters initialization|
|20|[Softmax_in_1D](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L20_softmax_in_1D.ipynb)| Building a Softmax classifier in 1D|
|21|[predicting_MNIST_using_Softmax](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L21_predicting_MNIST_using_Softmax.ipynb)| Classify handwritten digits from the MNIST database by using Softmax classifier and visualize parameters learned for each class following model training|
|22|[simpleNN_1hiddenlayer](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L22_simpleNN_1hiddenlayer.ipynb)| Simple Neural Network with 1 hidden layer|
|23|[NN_more_hidden_neurons](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L23_NN_more_hidden_neurons.ipynb)| Neural Network with 1 hidden layer (more neurons)|
|24|[Neural_network](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L24_Neural_network.ipynb)| Building a neural network with 1 hidden layer to classify noisy XOR data|

## Ipython notebooks of [Introduction to Deep Learning & Neural Networks with Keras](https://www.coursera.org/learn/introduction-to-deep-learning-with-keras)
| # | **File name** |  **Description** |
| ---------- |--------- | ------------------------------------------------| 
|1|[Forward_Propagation](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L1-Forward-Propagation.ipynb)|An example code to demonstrate how a neural network performs predictions using forward propagation|
|2|[Regression_with_Keras](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L2-Regression-with-Keras.ipynb)|Building a neural network for a regression problem|
|3|[Classification_with_Keras](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L3-Classification-with-Keras.ipynb)|Building a neural network for a classification problem using MNIST dataset|
|4|[Convolutional_Neural_Networks](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/L4-Convolutional-Neural-Networks-with-Keras.ipynb)|Building a convolutional neural network with user defined convolutional and pooling layers|
